services:
    spark:
        image: docker.io/bitnami/spark:3
        networks:
            - proj-network
        environment:
            - SPARK_MODE=master
            - SPARK_RPC_AUTHENTICATION_ENABLED=no
            - SPARK_RPC_ENCRYPTION_ENABLED=no
            - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
            - SPARK_SSL_ENABLED=no
        ports:
            - "8080:8080"

    spark-worker:
        image: docker.io/bitnami/spark:3
        networks:
            - proj-network
        environment:
            - SPARK_MODE=worker
            - SPARK_MASTER_URL=spark://spark:7077
            - SPARK_WORKER_MEMORY=1G
            - SPARK_WORKER_CORES=1
            - SPARK_RPC_AUTHENTICATION_ENABLED=no
            - SPARK_RPC_ENCRYPTION_ENABLED=no
            - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
            - SPARK_SSL_ENABLED=no

    kafka-server:
        image: bitnami/kafka:latest
        container_name: kafka-server
        networks:
            - proj-network
        ports:
            - "9092:9092"
        environment:
            - KAFKA_KRAFT_CLUSTER_ID=kraft-cluster-id-1234
            - KAFKA_CFG_NODE_ID=1
            - KAFKA_CFG_PROCESS_ROLES=broker,controller
            - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
            - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka-server:9092
            - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka-server:9093
            - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
            - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
            - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
            - ALLOW_PLAINTEXT_LISTENER=yes
        healthcheck:
            test: ["CMD", "bash", "-c", "echo > /dev/tcp/localhost/9092"]
            interval: 10s
            timeout: 5s
            retries: 5
            start_period: 20s

    kafka-init:
        image: bitnami/kafka:latest
        depends_on:
            - kafka-server
        networks:
            - proj-network
        entrypoint: ["sh", "-c"]
        command: >
            "
            sleep 20 &&
            kafka-topics.sh --create --bootstrap-server kafka-server:9092 --replication-factor 1 --partitions 3 --topic input_stream &&
            kafka-topics.sh --create --bootstrap-server kafka-server:9092 --replication-factor 1 --partitions 3 --topic output_stream
            "

    producer:
        build: 
            context: .
            dockerfile: Dockerfile.producer
        container_name: producer
        depends_on:
            kafka-server:
                condition: service_healthy
            # consumer:
            #     condition: service_started
        restart: on-failure
        networks:
            - proj-network

    spark-submit:
        image: bitnami/spark:3
        container_name: spark-submit
        command: >
            spark-submit
            --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0
            /opt/app/process_stream.py
        volumes:
            - ./app:/opt/app
        depends_on:
            - producer
            - spark
            - spark-worker
        networks:
            - proj-network
        stdin_open: true
        tty: true
        restart: "no"

    cassandra:
        image: cassandra:4.1
        container_name: cassandra
        networks:
            - proj-network
        ports:
            - "9042:9042"
        environment:
            - CASSANDRA_CLUSTER_NAME=wiki-cluster
            - CASSANDRA_DC=dc1
            - CASSANDRA_ENDPOINT_SNITCH=GossipingPropertyFileSnitch
        volumes:
            - cassandra_data:/var/lib/cassandra
        healthcheck:
            test: ["CMD", "cqlsh", "-e", "describe keyspaces"]
            interval: 30s
            timeout: 10s
            retries: 5

    cassandra-init:
        image: cassandra:4.1
        depends_on:
            cassandra:
                condition: service_healthy
        networks:
            - proj-network
        volumes:
            - ./cassandra:/cql
        entrypoint: [ "sh", "-c", "sleep 30 && cqlsh cassandra -f /cql/init.cql" ]


networks:
    proj-network:
        name: proj-network
volumes:
    kafka_data:
    cassandra_data:
